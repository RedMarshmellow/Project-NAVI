{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5db78bcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import cv2\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b5100572",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in C:\\Users\\hevra/.cache\\torch\\hub\\ultralytics_yolov5_master\n",
      "YOLOv5  2022-11-20 Python-3.9.12 torch-1.12.1+cpu CPU\n",
      "\n",
      "Fusing layers... \n",
      "YOLOv5s summary: 213 layers, 7225885 parameters, 0 gradients\n",
      "Adding AutoShape... \n"
     ]
    }
   ],
   "source": [
    "# Model\n",
    "model = torch.hub.load('ultralytics/yolov5', 'yolov5s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e1257d65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0 => person, 1 => bicycle, 2 => car, 3 => motorcycle, 5 => bus, 9 => traffic light, 13 => bench,\n",
    "# 15 => dog, 16 => cat, 56 => chair, 57 => couch, 59 => bed, 60 => dining table, 62 => t.v\n",
    "model.classes = [0, 1, 2, 3, 5, 9, 13, 15, 16, 56, 57, 59, 60, 62]  # (optional list) filter by class, i.e. = [0, 15, 16] for persons, cats and dogs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a80cea8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This dictionary will be utilized while finding the distance of objects from the user. \n",
    "# We are using the width of an object instead of its height because while capturing the \n",
    "# frame, the complete height of the object might not be captured. The width is more likely\n",
    "# to be appearing in full length.\n",
    "#'motorcycle': ,'traffic light': , 'bench': ,'dog': , 'cat': ,  'bed': , 'dining_table': , \n",
    "objects_actual_width = {'person': 38.5, 'tv':5, 'bicycle': 175, 'couch': 152, 'bus': 1200, 'car': 448, 'chair': 46}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a4f65060",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this function will calculate the distance of the object from the user\n",
    "# by using the values of the focal_length, which will be given from the frontend,\n",
    "# the actual_width of the object, which is already stored (the width of all the object of the same\n",
    "# class are considered to be equal), and the perceived_width, which is returned from the ML model\n",
    "def distance_calculation(focal_length, actual_width, perceived_width):\n",
    "    distance = focal_length * (actual_width / perceived_width)\n",
    "    return distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fab12687",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this function will take the prediction list from the ML model, which contains all the\n",
    "# objects detected in a given frame. It also gets the actual_width of all the objects, which\n",
    "# are already stored and the class_name dictionary, which specifies the name of the class\n",
    "# given its index. E.g. class '0' represents a car.\n",
    "def list_creation_objects_with_their_distances(predictions, objects_actual_width):\n",
    "    # this list will be forwarded to the method that finds the positions of objects, where the position\n",
    "    # information of the object will be appended to each dictionary element of the list.\n",
    "    objects_with_positions = []\n",
    "    # this for loop is used to find the distances of the objects that are found by the ml model\n",
    "    for instance in predictions:\n",
    "        print(instance['name'])\n",
    "        actual_width = objects_actual_width[instance['name'][0]]\n",
    "        perceived_width = instance['xmax'][0] - instance['xmin'][0]\n",
    "        focal_length = 2  # take this value from the frontend\n",
    "        distance = distance_calculation(focal_length, actual_width, perceived_width)\n",
    "        objects_with_positions.append({'object': instance['name'][0], 'distance': distance})\n",
    "\n",
    "    return objects_with_positions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b605c05d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculating the position of the detected object\n",
    "# The whole image is divided into three positions such as top, center and bottom \n",
    "# as row-wise and left, center and right as column-wise. \n",
    "\n",
    "# this function will take the prediction list from the ML model, which contains all the\n",
    "# objects detected in a given frame. additionally, it will also take the dictionary returned by the\n",
    "# list_creation_objects_with_their_distances and append the position information to the object name and object distance.\n",
    "# the return value will be a list of dictionaries, each dictionary holding the object name, object distance, and object position\n",
    "def list_creation_objects_with_their_positions(predictions, objects_with_positions, FRAME_WIDTH, FRAME_HEIGHT):\n",
    "    # this for loop is used to find the distances of the objects that are found by the ml model\n",
    "    for idx, instance in enumerate(predictions):\n",
    "        # the perceived width and height of the object\n",
    "        width = instance['xmax'][0] - instance['xmin'][0] \n",
    "        height = instance['ymax'][0] - instance['ymin'][0]\n",
    "        \n",
    "        # the x_center and y_center are the coordinates of the middle point of the bounding box  \n",
    "        # with respect to the origin which is (0,0).\n",
    "        # x_center can be found by taking the average of \n",
    "        # xmin which is the coordinate of the top left point of the bounding box with respect to the origin\n",
    "        # and the top right point. the top right is equal to top left plus the width. same logic for y_center.\n",
    "        x_center = ((2 * instance['xmin'][0]) + (width)) / 2\n",
    "        y_center = ((2 * instance['ymin'][0]) + (height)) / 2\n",
    "        \n",
    "    \n",
    "        if (x_center <= (FRAME_WIDTH/3)) and (y_center <= FRAME_HEIGHT/3):\n",
    "            position = \"TOP LEFT\"\n",
    "        elif (x_center <= (FRAME_WIDTH/3)) and (y_center <= (FRAME_HEIGHT/3)*2):\n",
    "            position = \"CENTER LEFT\"\n",
    "        elif (x_center <= (FRAME_WIDTH/3)) and (y_center <= FRAME_HEIGHT):\n",
    "            position = \"BOTTOM LEFT\"\n",
    "        elif (x_center <= (FRAME_WIDTH/3)*2) and (y_center <= FRAME_HEIGHT/3):\n",
    "            position = \"TOP CENTER\"\n",
    "        elif (x_center <= (FRAME_WIDTH/3)*2) and (y_center <= (FRAME_HEIGHT/3)*2):\n",
    "            position = \"CENTER CENTER\"\n",
    "        elif (x_center <= (FRAME_WIDTH/3)*2) and (y_center <= FRAME_HEIGHT):\n",
    "            position = \"BOTTOM CENTER\"\n",
    "        elif (y_center <= FRAME_HEIGHT/3):\n",
    "            position = \"TOP RIGHT\"\n",
    "        elif (y_center <= (FRAME_HEIGHT/3)*2):\n",
    "            position = \"CENTER RIGHT\"\n",
    "        else:\n",
    "            position = \"BOTTOM RIGHT\"\n",
    "        \n",
    "        \n",
    "        objects_with_positions[idx][\"position\"] = position\n",
    "        \n",
    "    return objects_with_positions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4988dd9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this function first performs distance calculation and then performs position calculation (top left, buttom right, etc). \n",
    "# its return value is a list of objects with their names, distances from the users, and position with respect to the user.\n",
    "# e.g. {'object': car, 'distance': 2.5 meters, 'position': top left}\n",
    "def calculate_position(predictions, objects_actual_width, FRAME_WIDTH, FRAME_HEIGHT):\n",
    "    objects_with_positions = list_creation_objects_with_their_distances(predictions, objects_actual_width)\n",
    "    objects_with_positions = list_creation_objects_with_their_positions(predictions, objects_with_positions, FRAME_WIDTH, FRAME_HEIGHT)\n",
    "    return objects_with_positions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "33954595",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating a binary file of our ml model, wb => write binary\n",
    "pickle.dump(model, open(\"object_detection-v1.pk\", \"wb\"))\n",
    "\n",
    "# creating a model object by loading the pickle file that we just created above\n",
    "model_pk = pickle.load(open(\"object_detection-v1.pk\", \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9861a23a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    person\n",
      "Name: name, dtype: object\n",
      "[{'object': 'person', 'distance': 0.20668033812489683, 'position': 'BOTTOM RIGHT'}]\n"
     ]
    }
   ],
   "source": [
    "cap = cv2.VideoCapture(0) # accessing webcam\n",
    "while cap.isOpened():\n",
    "    # capture image\n",
    "    ret, frame = cap.read()\n",
    "    \n",
    "    if ret == False:\n",
    "        print(\"Can't get the frames\")\n",
    "        ret, frame = cap.read()\n",
    "        \n",
    "    # make detections\n",
    "    results = model_pk(frame)\n",
    "    objects_with_positions = calculate_position(results.pandas().xyxy, objects_actual_width)\n",
    "    cv2.imshow('YOLO', np.squeeze(results.render()))\n",
    "    \n",
    "    # waiting using waitKey method\n",
    "    cv2.waitKey(2000)\n",
    "\n",
    "    if cv2.waitKey(0) & 0xFF == ord('q'):\n",
    "        break\n",
    "print(objects_with_positions)\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf36d670",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e3b7d71",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
